########################
# GLOBAL CONFIG PARAMS #
########################
log_level = info

########### 
# Capture #
###########

# Capture source. This is WIFF's data source. In can be a WIFF processor (as
# defined in another section), a capture file, a folder containing capture 
# files (they will be read in order of creation), a network interface name,
# or the index of a network interface in the list of all available interfaces.
capture_source = captures

# ByteBuffer Pool Size. This is number of megabytes to use as temporary storage
# for packet data retrieved from the capture source (except for processors).
# A larger pool gives WIFF more time to process packets, increase this number if
# you see a large packet drop rate.
pool_size = 200

# ByteBuffer Capacity. The size of each buffer in the pool. This must be greater
# than or equal to the number of bytes in the largest packet processed. The 
# theoretical max size is 65535 bytes.
buffer_capacity= 50000

# Optional tcp dump filter (not applied to data retrieved from processors)
tcpdump_filter = port 80

# SSL Port. If this is the client's destination port, WIFF will attempt to 
# decrypt the traffic
ssl_port = 443

# Server's SSL Private Key(s). Only RSA is supported for now. This may be a single
# .key file or a file containing a mapping in the format below of IPs to key files.
# <unique ip address> <key file> 
# <unique ip address> <key file> 
# ...
ssl_rsa_private_key =

##############
# Processors #
##############
# Processors are alternative data sources for WIFF. The following processor
# retrieves data from RabbitMQ
wiff.processor.rabbit.type = RabbitMQProcessor
wiff.processor.rabbit.host = 
wiff.processor.rabbit.port = 5672
wiff.processor.rabbit.user = 
wiff.processor.rabbit.pass = 
wiff.processor.rabbit.queue = 

#############
# Consumers #
#############

# The number of threads that process incoming data
consumer_count = 20  

# The type of consumer.
consumer_type = PacketConsumer

############
# Services #
############
# Services are objects to which all incoming data is sent. A service will
# extract the information it cares about and, at some point, send some
# processed data to a reporter.

# The list of services to which the incoming data will be sent
wiff.services = Stitching

# The Stitching service will stitch together related packets and sends the
# reporter defined as "rabbit" in the report section. If a related packet 
# is not seen for 20 seconds (cache time) the stream is considered complete.
wiff.service.Stitching.type = WiffStitch
wiff.service.Stitching.cachetime = 20
wiff.service.Stitching.reporter = rabbit

#############
# Reporters #
#############
# Reporters are responsible for transmitting data to external applications.

# The reporter below, "rabbit", sends data to RabbitMQ
wiff.reporter.rabbit.type = RabbitMQClient
wiff.reporter.rabbit.host = 
wiff.reporter.rabbit.port = 5672
wiff.reporter.rabbit.user = 
wiff.reporter.rabbit.pass = 
wiff.reporter.rabbit.exchange = 
wiff.reporter.rabbit.queue = 
wiff.reporter.rabbit.report_interval = 0
wiff.reporter.rabbit.parser = tcp 

###########
# Parsers #
###########
# Parsers can be used to transform data before it is sent by a reporter to an
# external application.

# The HTTP parser "tcp" will extract the headers and body (optional) from
# a tcp stream containing HTTP messages and format them using the Elasticsearch
# bulk API syntax.
wiff.parser.tcp.type = HTTPParser
wiff.parser.tcp.index_name = wiff
wiff.parser.tcp.include_body = false
wiff.parser.tcp.input_source = <host_name>
wiff.parser.tcp.data_source = web

# The PrependSize parser "prepend" will prepend the size (4 byte integer) of a
# byte array to itself 
wiff.parser.prepend.type = PrependSize


# The ESBulkIndex parser "bulkapi" wrap json in an Elasticsearch Bulk API index message
wiff.parser.bulkapi.type = ESBulkIndex
wiff.parser.bulkapi.index_name = 
